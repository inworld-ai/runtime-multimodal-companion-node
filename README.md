### Overview

This service is a Node.js backend built on Inworld Runtime (0.5) that powers:
- Real‑time Speech‑to‑Text (STT) over WebSocket
- Image+Text → LLM → TTS streaming ("ImageChat") over WebSocket
- Optional HTTP test endpoints for quick local validation

Unity connects via HTTP to create a session token, then upgrades to WebSocket for interactive audio/text/image exchange.

### Repository Layout (server-side)
- `index.ts`
  - Express HTTP server, WebSocket upgrade, session/token issuance, auth checks
  - Optional HTTP `/chat` endpoint (not required if using WebSocket only)
- `message_handler.ts`
  - Parses client messages (TEXT, AUDIO, AUDIO_SESSION_END, IMAGE_CHAT)
  - Orchestrates STT executions and ImageChat (LLM→Chunk→TTS) streaming
- `stt_graph.ts`
  - Builds a single, long-lived STT GraphExecutor used across the process
- `auth.ts`
  - HMAC auth verification for HTTP/WS (compatible with Unity `InworldAuth`)
- `constants.ts`
  - Defaults for audio sample rates, VAD thresholds, text generation config
- `test-audio.html`, `test-image-chat.html`
  - Local test pages for quick validation without Unity

### Runtime Requirements
- Node.js 18+
- TypeScript 5+
- Inworld Runtime SDK 0.5 (breaking changes vs 0.4.x)

### Quick Start (with .env-sample)
1) Copy env template and edit values
```bash
cp .env-sample .env
# Edit .env and set INWORLD_API_KEY (base64("apiKey:apiSecret")) and VAD_MODEL_PATH. Optionally set ALLOW_TEST_CLIENT for local HTML testing.
```

2) Install & Run
```bash
yarn install
yarn build
yarn start
```

Server output (expected):
- "VAD client initialized"
- "STT Graph initialized"
- "Server running on http://localhost:<PORT>"
- "WebSocket available at ws://localhost:<PORT>/ws?key=<session_key>"

### Environment Variables
- Required
  - `INWORLD_API_KEY`: base64("apiKey:apiSecret")
  - `VAD_MODEL_PATH`: local path to the VAD model (e.g., `silero_vad.onnx`)
- Optional
  - `PORT`: server port (default 3000)
  - `HTTP_CHAT_MAX_CONCURRENCY`: throttle HTTP `/chat` concurrency (if enabled)
  - `ALLOW_TEST_CLIENT`: when set to `true`, enables `GET /get_access_token` to issue short‑lived `{ sessionKey, wsToken }` for local HTML tests. Do NOT enable in production.

Example `.env` (you can start from `.env-sample`):
```bash
INWORLD_API_KEY=xxxxxx_base64_apiKey_colon_apiSecret
VAD_MODEL_PATH=silero_vad.onnx
PORT=3000
# Enable local HTML test helper endpoint (development only)
# ALLOW_TEST_CLIENT=true
```

### Local HTML Testing (no auth code in browser)
- Enable local helper endpoint (optional, for development): set `ALLOW_TEST_CLIENT=true` in `.env`.
- Start the server and open the test pages:
  - `http://localhost:<PORT>/test-audio`
  - `http://localhost:<PORT>/test-image`
- The pages will call `GET /get_access_token` to obtain `{ sessionKey, wsToken }`, then connect to `ws://host/ws?key=...&wsToken=...`.
- Verify helper endpoint works: open `http://localhost:<PORT>/get_access_token` and expect `{ sessionKey, wsToken }`.

Security note: `ALLOW_TEST_CLIENT` is for local/dev only. Keep it disabled in production.

### ALLOW_TEST_CLIENT
- What it is: a development-only feature flag. When set to `true`, the server exposes `GET /get_access_token` that returns short‑lived, single‑use `{ sessionKey, wsToken }` for the HTML test pages. This avoids putting auth/signing code or secrets in the browser.
- How to enable:
  - Via `.env`: add `ALLOW_TEST_CLIENT=true` and restart the server.
  - Via Windows PowerShell (current session): `$env:ALLOW_TEST_CLIENT = "true"`
  - Persistently (PowerShell): `setx ALLOW_TEST_CLIENT "true"` then open a new terminal.
- Verify: open `http://localhost:<PORT>/get_access_token`. You should get `{ sessionKey, wsToken }`.
- Security: do NOT enable in production. Tokens are short‑lived (5 minutes) and single‑use, but the endpoint is intended only for local development.

### Auth Model
- HTTP endpoints require HMAC header `Authorization: IW1-HMAC-SHA256 ...` (see `auth.ts`), generated by Unity `InworldAuth`.
- WebSocket:
  - Preferred: obtain a short-lived `wsToken` from `POST /create-session` and connect to `/ws?key=<sessionKey>&wsToken=<token>`
  - Fallback: full `Authorization` header on the upgrade request (not recommended for clients)

### HTTP Endpoints (optional)
- `POST /create-session` (protected)
  - Returns `{ sessionKey, wsToken }`
  - `wsToken` is single-use, short-lived
- `POST /chat` (protected, optional)
  - Accepts `prompt` and an optional `image` file (multipart)
  - Runs a one‑off LLM graph (non‑streaming) and returns `{ response }`

### WebSocket Flow
1) Client calls `POST /create-session` (with HMAC auth) → `{ sessionKey, wsToken }`
2) Client connects: `ws://host/ws?key=<sessionKey>&wsToken=<token>`
3) Client sends messages; server returns text/audio and `INTERACTION_END` packets

Client → Server messages:
- `{ type: "text", text: string }`
- `{ type: "audio", audio: number[][] }`  // streamed float32 chunks
- `{ type: "audioSessionEnd" }`            // finalize the STT turn
- `{ type: "imageChat", text: string, image: string, voiceId?: string }` // image is data URL (base64)

Server → Client messages:
- `TEXT`: `{ text: { text, final }, routing: { source: { isAgent|isUser, name } } }`
- `AUDIO`: `{ audio: { chunk: base64_wav } }` (streamed for TTS)
- `INTERACTION_END`: marks end of one turn / execution
- `ERROR`: `{ error }`

### Graphs & Executors
- STT Graph
  - Constructed once at server startup (`stt_graph.ts`), reused for all STT requests
  - For each STT turn: `executor.start(input, executionId)` → read first result → `closeExecution`
- ImageChat Graph (LLM→TextChunking→TTS)
  - Per WebSocket connection: one shared executor reused across image+text turns
  - Rebuilt only if `voiceId` changes for that connection
  - For each ImageChat turn: `executor.start(LLMChatRequest, executionId)` → stream TTS chunks → `closeExecution`

### Inworld Runtime 0.5 Notes
- Use builder signature: `new GraphBuilder({ id, apiKey }).build()` (not `.getExecutor()`)
- Use nodes: `new RemoteLLMChatNode(...)`, `new TextChunkingNode(...)`, `new RemoteTTSNode(...)`
- Start executions with `executor.start(input, executionId)` (not `.execute()`)
- LLM input type: `new GraphTypes.LLMChatRequest({ messages })` (not plain `{ messages }`)

### Model Provider & Config
- LLM provider/model examples
  - OpenAI: `{ provider: 'openai', modelName: 'gpt-4o-mini', stream: true|false }`
  - Google Gemini: `{ provider: 'google', modelName: 'gemini-2.5-flash-lite', stream: true }`
- Text generation (see `constants.ts` → `TEXT_CONFIG`)
  - `temperature`, `topP`, `maxNewTokens`, penalties, etc.
  - Typical: higher `temperature`/`topP` → more diverse; lower → more deterministic

### Audio & VAD
- Input sample rate: 16 kHz (Unity mic)
- VAD: Silero VAD (ONNX) local inference for voice activity detection
- STT turn starts on voiced audio and finalizes when pauses exceed a threshold (`PAUSE_DURATION_THRESHOLD_MS`)

### Error Semantics & Recovery
- gRPC `Deadline Exceeded`: single execution timed out; treat as recoverable (retry once)
- HTTP/2 `GOAWAY ENHANCE_YOUR_CALM` (`too_many_pings`): server throttling of idle keepalives; treat as recoverable, rebuild channel/executor on next use
- WebSocket "closed without close handshake": usually process restart/crash or proxy idle-kill; implement client auto‑reconnect (backoff)
- "Your graph is not registered": informational warning about remote variants; safe to ignore unless you explicitly use registry-managed graphs

### Concurrency & Resource Guidelines
- STT executor is global and reused (fast first token)
- ImageChat executor is per WebSocket connection and reused; serialize turns per connection
- Optionally enforce small concurrency limits for HTTP `/chat` if enabled
- Always `closeExecution(outputStream)` after reading results

### Deployment Tips (e.g., Railway)
- Keep concurrency conservative (2–4) unless the plan allows more resources
- Prefer long-lived shared executors with per‑turn `start(...)`/`closeExecution(...)`
- Expect GOAWAY after long idle periods; allow light retry or lazy re‑init on next turn

### Local Testing
- Open `http://localhost:<PORT>/test-audio` to stream mic audio
- Open `http://localhost:<PORT>/test-image` to submit a prompt + image

### Troubleshooting
- LLM input mismatch on 0.5: ensure `GraphTypes.LLMChatRequest({ messages })` and `executor.start(...)`
- No image update: confirm Unity captures a fresh image before each `imageChat` send
- Long STT delay: verify VAD thresholds and that `audioSessionEnd` is sent after speech
- Frequent GOAWAY on idle: acceptable; ensure executions are closed and executors are reused


